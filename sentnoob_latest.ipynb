{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYU_5lSw1VKq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()\n",
        "\n"
      ],
      "metadata": {
        "id": "zKic9kut3z4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"Train.csv\")\n",
        "val   = pd.read_csv(\"Val.csv\")\n",
        "test  = pd.read_csv(\"Test.csv\")\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Columns:\", train.columns)\n",
        "train.head(3)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_F4Db3WT4ap1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train labels:\", sorted(train[\"Label\"].unique()))\n",
        "print(\"Val labels:\", sorted(val[\"Label\"].unique()))\n",
        "print(\"Test labels:\", sorted(test[\"Label\"].unique()))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h-_75VqS59n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train[\"Label\"].value_counts())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KA877d5n6Af8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "clf = pipeline(\"text-classification\", model=MODEL_NAME)\n",
        "\n",
        "print(clf(\"আমি আজকে খুব খুশি\"))\n",
        "print(clf(\"খুব খারাপ সার্ভিস\"))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5qq7PVps6Jiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Make a clean copy with standard column names\n",
        "train_df = train.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "val_df   = val.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "test_df  = test.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "\n",
        "# Convert label to int\n",
        "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
        "val_df[\"label\"]   = val_df[\"label\"].astype(int)\n",
        "test_df[\"label\"]  = test_df[\"label\"].astype(int)\n",
        "\n",
        "train_df.head(3)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "39Gl_vTw7Yme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_label = min(train_df[\"label\"].unique())\n",
        "print(\"Min label:\", min_label)\n"
      ],
      "metadata": {
        "id": "2AaJUxSQ7aTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers accelerate datasets evaluate\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ielVetci7xHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade --no-cache-dir \\\n",
        "  \"pandas==2.2.2\" \\\n",
        "  \"requests==2.32.4\"\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mysNzkoKD_ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade --no-cache-dir \\\n",
        "  \"pyarrow>=21.0.0\" \\\n",
        "  \"datasets>=4.5.0\" \\\n",
        "  \"transformers\" \"accelerate\" \"evaluate\" \"scikit-learn\"\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DhIwTHwTFX-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "import pyarrow as pa, datasets, transformers\n",
        "\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"pyarrow:\", pa.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNk4HHwSFl5i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AIqCe--WHznp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "zH42B20ZIAAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppYhuRf0ICBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "import evaluate\n",
        "\n",
        "MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "# number of classes from your data\n",
        "NUM_LABELS = len(sorted(train_df[\"label\"].unique()))\n",
        "print(\"NUM_LABELS =\", NUM_LABELS)\n",
        "\n",
        "# ✅ define tokenizer first\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ✅ then create collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def to_ds(df):\n",
        "    df = df[[\"text\",\"label\"]].copy()\n",
        "    df[\"text\"] = df[\"text\"].astype(str)\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "train_ds = to_ds(train_df)\n",
        "val_ds   = to_ds(val_df)\n",
        "test_ds  = to_ds(test_df)\n",
        "\n",
        "def tok(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True)\n",
        "\n",
        "train_ds = train_ds.map(tok, batched=True)\n",
        "val_ds   = val_ds.map(tok, batched=True)\n",
        "test_ds  = test_ds.map(tok, batched=True)\n",
        "\n",
        "train_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "val_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "test_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=NUM_LABELS, ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "f1  = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"macro_f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"xlmr_finetuned_bn\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(\"FINAL TEST:\", trainer.evaluate(test_ds))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OYzsTaGD7ew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "pred = trainer.predict(test_ds)\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "y_true = pred.label_ids\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "id": "KK85AjRHPL8Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions on test set\n",
        "pred = trainer.predict(test_ds)\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "y_true = pred.label_ids  # safest (from dataset)\n",
        "\n",
        "# Label names MUST match your numeric labels (0,1,2)\n",
        "label_names = [\"neutral\", \"positive\", \"negative\"]   # change if your mapping is different\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "hl6UkqvmTGkn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no-preprocessing\n",
        "def run_experiment(train_df, val_df, test_df, exp_name=\"baseline\"):\n",
        "    import numpy as np\n",
        "    from datasets import Dataset\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "    from transformers import DataCollatorWithPadding\n",
        "    import evaluate\n",
        "\n",
        "    MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "    NUM_LABELS = len(sorted(train_df[\"label\"].unique()))\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    def to_ds(df):\n",
        "        df = df[[\"text\",\"label\"]].copy()\n",
        "        df[\"text\"] = df[\"text\"].astype(str)\n",
        "        df[\"label\"] = df[\"label\"].astype(int)\n",
        "        return Dataset.from_pandas(df)\n",
        "\n",
        "    train_ds = to_ds(train_df)\n",
        "    val_ds   = to_ds(val_df)\n",
        "    test_ds  = to_ds(test_df)\n",
        "\n",
        "    def tok(batch):\n",
        "        return tokenizer(batch[\"text\"], truncation=True, max_length=128)\n",
        "\n",
        "    train_ds = train_ds.map(tok, batched=True)\n",
        "    val_ds   = val_ds.map(tok, batched=True)\n",
        "    test_ds  = test_ds.map(tok, batched=True)\n",
        "\n",
        "    train_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "    val_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "    test_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME, num_labels=NUM_LABELS, ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    acc = evaluate.load(\"accuracy\")\n",
        "    f1  = evaluate.load(\"f1\")\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=1)\n",
        "        return {\n",
        "            \"accuracy\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "            \"macro_f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "        }\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"out_{exp_name}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"macro_f1\",\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    val_result  = trainer.evaluate(val_ds)\n",
        "    test_result = trainer.evaluate(test_ds)\n",
        "\n",
        "    return val_result, test_result"
      ],
      "metadata": {
        "id": "sTYP1NEKpKJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run without preprocessing\n",
        "# Create standardized dataframes\n",
        "train_df = train.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "val_df   = val.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "test_df  = test.rename(columns={\"Data\":\"text\", \"Label\":\"label\"}).copy()\n",
        "\n",
        "# Make sure labels are integers\n",
        "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
        "val_df[\"label\"]   = val_df[\"label\"].astype(int)\n",
        "test_df[\"label\"]  = test_df[\"label\"].astype(int)\n",
        "\n",
        "print(train_df.columns)\n",
        "train_df.head(3)"
      ],
      "metadata": {
        "id": "_ZcTxfhhpL04",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_base, test_base = run_experiment(train_df, val_df, test_df, \"baseline\")\n",
        "print(\"BASELINE VAL:\", val_base)\n",
        "print(\"BASELINE TEST:\", test_base)"
      ],
      "metadata": {
        "id": "mFKz2ecxpPNY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Put this “Preprocessing Functions” cell once\n",
        "import re, unicodedata\n",
        "\n",
        "# remove invisible characters common in Bangla copy-paste\n",
        "ZERO_WIDTH = r\"[\\u200b\\u200c\\u200d\\uFEFF]\"\n",
        "multi_space_re = re.compile(r\"\\s+\")\n",
        "\n",
        "url_re = re.compile(r\"http\\S+|www\\.\\S+\")\n",
        "mention_re = re.compile(r\"@\\w+\")\n",
        "rt_re = re.compile(r\"^RT\\s+@\\w+:\\s*\")\n",
        "\n",
        "repeat_punct_re = re.compile(r\"([!?।])\\1{2,}\")   # !!!!! or ????\n",
        "\n",
        "bn_to_en_digits = str.maketrans(\"০১২৩৪৫৬৭৮৯\", \"0123456789\")\n",
        "\n",
        "def preprocess_v1(text: str) -> str:\n",
        "    \"\"\"V1: Safe cleaning (Unicode normalize + zero-width remove + spacing)\"\"\"\n",
        "    text = \"\" if text is None else str(text)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = re.sub(ZERO_WIDTH, \"\", text)\n",
        "    text = multi_space_re.sub(\" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def preprocess_v2(text: str) -> str:\n",
        "    \"\"\"V2: Twitter normalization (V1 + mask URL + mask USER + remove RT header)\"\"\"\n",
        "    text = preprocess_v1(text)\n",
        "    text = rt_re.sub(\"\", text)\n",
        "    text = url_re.sub(\" [URL] \", text)\n",
        "    text = mention_re.sub(\" [USER] \", text)\n",
        "    text = multi_space_re.sub(\" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def preprocess_v3(text: str) -> str:\n",
        "    \"\"\"V3: V2 + normalize Bangla digits + compress repeated punctuation\"\"\"\n",
        "    text = preprocess_v2(text)\n",
        "    text = text.translate(bn_to_en_digits)\n",
        "    text = repeat_punct_re.sub(r\"\\1\\1\", text)  # \"!!!!!\" -> \"!!\"\n",
        "    text = multi_space_re.sub(\" \", text).strip()\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "mtjQqPEkp72z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run your 3 preprocessing experiments (like baseline)\n",
        "#Preprocess V1 experiment\n",
        "train_v1 = train_df.copy()\n",
        "val_v1   = val_df.copy()\n",
        "test_v1  = test_df.copy()\n",
        "\n",
        "for df in [train_v1, val_v1, test_v1]:\n",
        "    df[\"text\"] = df[\"text\"].apply(preprocess_v1)\n",
        "\n",
        "val_v1_res, test_v1_res = run_experiment(train_v1, val_v1, test_v1, \"preprocess_v1\")\n",
        "print(\"V1 VAL:\", val_v1_res)\n",
        "print(\"V1 TEST:\", test_v1_res)\n",
        "\n"
      ],
      "metadata": {
        "id": "M4V8srOdqMqB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess V2 experiment\n",
        "\n",
        "train_v2 = train_df.copy()\n",
        "val_v2   = val_df.copy()\n",
        "test_v2  = test_df.copy()\n",
        "\n",
        "for df in [train_v2, val_v2, test_v2]:\n",
        "    df[\"text\"] = df[\"text\"].apply(preprocess_v2)\n",
        "\n",
        "val_v2_res, test_v2_res = run_experiment(train_v2, val_v2, test_v2, \"preprocess_v2\")\n",
        "print(\"V2 VAL:\", val_v2_res)\n",
        "print(\"V2 TEST:\", test_v2_res)\n"
      ],
      "metadata": {
        "id": "vtBUcJISqQIA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess V3 experiment\n",
        "train_v3 = train_df.copy()\n",
        "val_v3   = val_df.copy()\n",
        "test_v3  = test_df.copy()\n",
        "\n",
        "for df in [train_v3, val_v3, test_v3]:\n",
        "    df[\"text\"] = df[\"text\"].apply(preprocess_v3)\n",
        "\n",
        "val_v3_res, test_v3_res = run_experiment(train_v3, val_v3, test_v3, \"preprocess_v3\")\n",
        "print(\"V3 VAL:\", val_v3_res)\n",
        "print(\"V3 TEST:\", test_v3_res)\n"
      ],
      "metadata": {
        "id": "tGUsIDyPqSlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare results nicely\n",
        "results = {\n",
        "    \"baseline\": (val_base[\"eval_macro_f1\"], test_base[\"eval_macro_f1\"]),\n",
        "    \"v1\": (val_v1_res[\"eval_macro_f1\"], test_v1_res[\"eval_macro_f1\"]),\n",
        "    \"v2\": (val_v2_res[\"eval_macro_f1\"], test_v2_res[\"eval_macro_f1\"]),\n",
        "    \"v3\": (val_v3_res[\"eval_macro_f1\"], test_v3_res[\"eval_macro_f1\"]),\n",
        "}\n",
        "\n",
        "for k, (v_f1, t_f1) in results.items():\n",
        "    print(f\"{k:8s} | VAL macro-F1: {v_f1:.4f} | TEST macro-F1: {t_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "8aHyKfeFrhWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "6fQSeJI71pyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "LyBaLrPl1sZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/colab_project\n"
      ],
      "metadata": {
        "id": "L--S7-et1sll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv out_baseline /content/drive/MyDrive/colab_project/\n",
        "!mv out_preprocess_v1 /content/drive/MyDrive/colab_project/\n",
        "!mv out_preprocess_v2 /content/drive/MyDrive/colab_project/\n",
        "!mv sample_data /content/drive/MyDrive/colab_project/\n",
        "!mv xlmr_finetuned_bn /content/drive/MyDrive/colab_project/\n",
        "\n",
        "!mv Train.csv /content/drive/MyDrive/colab_project/\n",
        "!mv Val.csv /content/drive/MyDrive/colab_project/\n",
        "!mv Test.csv /content/drive/MyDrive/colab_project/\n"
      ],
      "metadata": {
        "id": "qXw_LyQk1wMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k2mU9plC1wW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}